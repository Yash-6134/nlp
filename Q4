from nltk.corpus import wordnet as wn
from nltk import pos_tag, word_tokenize
from tabulate import tabulate

def penn_to_wn(tag):
    if tag.startswith('N'): return wn.NOUN
    if tag.startswith('V'): return wn.VERB
    if tag.startswith('J'): return wn.ADJ   # adjectives are 'J' in Penn
    if tag.startswith('R'): return wn.ADV   # adverbs
    return None

sentence = input("Enter a sentence: ")

tokens = word_tokenize(sentence)
tags = pos_tag(tokens)

rows = []
for w, t in tags:
    if not (t.startswith(('N','V','J'))):   # keep your original filter
        continue
    wn_pos = penn_to_wn(t)
    syns = wn.synsets(w, pos=wn_pos) if wn_pos else wn.synsets(w)
    if not syns:
        rows.append([w.lower(), "None", "None", "None"])
        continue
    s = syns[0]
    syn = s.lemmas()[0].name() if s.lemmas() else "None"
    hyp = s.hypernyms()[0].lemmas()[0].name() if s.hypernyms() else "None"
    hypo = s.hyponyms()[0].lemmas()[0].name() if s.hyponyms() else "None"
    rows.append([w.lower(), syn, hyp, hypo])

print("\nSemantic Relationships (Using WordNet):\n")
print(tabulate(rows, headers=["Word","Synonym","Hypernym","Hyponym"], tablefmt="grid"))
